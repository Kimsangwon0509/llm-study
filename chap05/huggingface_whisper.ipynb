{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T10:53:20.939544Z",
     "start_time": "2025-07-23T10:53:19.971921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade transformers datasets[audio] accelerate\n"
   ],
   "id": "827b725082145c9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/gse/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages (25.1.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "zsh:1: no matches found: datasets[audio]\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T07:07:20.149844Z",
     "start_time": "2025-07-16T07:07:20.146929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['PATH'] += os.pathsep + '/Users/gse/PycharmProjects/ffmpeg-2025-07-12-git-35a6de137a-full_build/bin'"
   ],
   "id": "a3a152221f0a0c71",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T07:07:34.625074Z",
     "start_time": "2025-07-16T07:07:20.282682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "# from datasets import load_dataset\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps = True,\n",
    "    chunk_length_s = 10,\n",
    "    stride_length_s = 2,\n",
    ")\n",
    "\n",
    "#dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "#sample = dataset[0][\"audio\"]\n",
    "sample = \"./audio/lsy_audio_2023_58s.mp3\"\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result)\n",
    "\n",
    "#print(result[\"text\"])\n"
   ],
   "id": "913fbb9fd769846c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ffmpeg was not found but is required to load audio files from filename",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/audio_utils.py:34\u001B[39m, in \u001B[36mffmpeg_read\u001B[39m\u001B[34m(bpayload, sampling_rate)\u001B[39m\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43msubprocess\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mffmpeg_command\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstdin\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubprocess\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPIPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstdout\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubprocess\u001B[49m\u001B[43m.\u001B[49m\u001B[43mPIPE\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m ffmpeg_process:\n\u001B[32m     35\u001B[39m         output_stream = ffmpeg_process.communicate(bpayload)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.12.8/lib/python3.12/subprocess.py:1026\u001B[39m, in \u001B[36mPopen.__init__\u001B[39m\u001B[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001B[39m\n\u001B[32m   1023\u001B[39m             \u001B[38;5;28mself\u001B[39m.stderr = io.TextIOWrapper(\u001B[38;5;28mself\u001B[39m.stderr,\n\u001B[32m   1024\u001B[39m                     encoding=encoding, errors=errors)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1027\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1028\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1029\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1030\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1031\u001B[39m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1032\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1033\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1034\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprocess_group\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1035\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[32m   1036\u001B[39m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/3.12.8/lib/python3.12/subprocess.py:1955\u001B[39m, in \u001B[36mPopen._execute_child\u001B[39m\u001B[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001B[39m\n\u001B[32m   1954\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m err_filename \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1955\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001B[32m   1956\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'ffmpeg'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     27\u001B[39m \u001B[38;5;66;03m#dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\u001B[39;00m\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m#sample = dataset[0][\"audio\"]\u001B[39;00m\n\u001B[32m     29\u001B[39m sample = \u001B[33m\"\u001B[39m\u001B[33m./audio/lsy_audio_2023_58s.mp3\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m result = \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[38;5;28mprint\u001B[39m(result)\n\u001B[32m     34\u001B[39m \u001B[38;5;66;03m#print(result[\"text\"])\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:271\u001B[39m, in \u001B[36mAutomaticSpeechRecognitionPipeline.__call__\u001B[39m\u001B[34m(self, inputs, **kwargs)\u001B[39m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Union[np.ndarray, \u001B[38;5;28mbytes\u001B[39m, \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mdict\u001B[39m], **kwargs: Any) -> \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]]:\n\u001B[32m    215\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    216\u001B[39m \u001B[33;03m    Transcribe the audio sequence(s) given as inputs to text. See the [`AutomaticSpeechRecognitionPipeline`]\u001B[39;00m\n\u001B[32m    217\u001B[39m \u001B[33;03m    documentation for more information.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    269\u001B[39m \u001B[33;03m                `\"\".join(chunk[\"text\"] for chunk in output[\"chunks\"])`.\u001B[39;00m\n\u001B[32m    270\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m271\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/base.py:1456\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[39m\n\u001B[32m   1454\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001B[32m   1455\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.framework == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ChunkPipeline):\n\u001B[32m-> \u001B[39m\u001B[32m1456\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m   1457\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m   1458\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_iterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1459\u001B[39m \u001B[43m                \u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\n\u001B[32m   1460\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1461\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1462\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1463\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1464\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:124\u001B[39m, in \u001B[36mPipelineIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    121\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_item()\n\u001B[32m    123\u001B[39m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m item = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    125\u001B[39m processed = \u001B[38;5;28mself\u001B[39m.infer(item, **\u001B[38;5;28mself\u001B[39m.params)\n\u001B[32m    126\u001B[39m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:269\u001B[39m, in \u001B[36mPipelinePackIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    266\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m accumulator\n\u001B[32m    268\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_last:\n\u001B[32m--> \u001B[39m\u001B[32m269\u001B[39m     processed = \u001B[38;5;28mself\u001B[39m.infer(\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m, **\u001B[38;5;28mself\u001B[39m.params)\n\u001B[32m    270\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.loader_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    271\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed, torch.Tensor):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/torch/utils/data/dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    731\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    736\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    739\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/torch/utils/data/dataloader.py:789\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    788\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m789\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    791\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:33\u001B[39m, in \u001B[36m_IterableDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     31\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index:\n\u001B[32m     32\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m         data.append(\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset_iter\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     34\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m     35\u001B[39m         \u001B[38;5;28mself\u001B[39m.ended = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py:186\u001B[39m, in \u001B[36mPipelineChunkIterator.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    183\u001B[39m     \u001B[38;5;28mself\u001B[39m.subiterator = \u001B[38;5;28mself\u001B[39m.infer(\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.iterator), **\u001B[38;5;28mself\u001B[39m.params)\n\u001B[32m    184\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    185\u001B[39m     \u001B[38;5;66;03m# Try to return next item\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m186\u001B[39m     processed = \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msubiterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    187\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[32m    188\u001B[39m     \u001B[38;5;66;03m# When a preprocess iterator ends, we can start lookig at the next item\u001B[39;00m\n\u001B[32m    189\u001B[39m     \u001B[38;5;66;03m# ChunkIterator will keep feeding until ALL elements of iterator\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    192\u001B[39m     \u001B[38;5;66;03m# Another way to look at it, is we're basically flattening lists of lists\u001B[39;00m\n\u001B[32m    193\u001B[39m     \u001B[38;5;66;03m# into a single list, but with generators\u001B[39;00m\n\u001B[32m    194\u001B[39m     \u001B[38;5;28mself\u001B[39m.subiterator = \u001B[38;5;28mself\u001B[39m.infer(\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m.iterator), **\u001B[38;5;28mself\u001B[39m.params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py:358\u001B[39m, in \u001B[36mAutomaticSpeechRecognitionPipeline.preprocess\u001B[39m\u001B[34m(self, inputs, chunk_length_s, stride_length_s)\u001B[39m\n\u001B[32m    355\u001B[39m             inputs = f.read()\n\u001B[32m    357\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m358\u001B[39m     inputs = \u001B[43mffmpeg_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeature_extractor\u001B[49m\u001B[43m.\u001B[49m\u001B[43msampling_rate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    360\u001B[39m stride = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    361\u001B[39m extra = {}\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.pyenv/versions/llm-exercise-3.12.8/lib/python3.12/site-packages/transformers/pipelines/audio_utils.py:37\u001B[39m, in \u001B[36mffmpeg_read\u001B[39m\u001B[34m(bpayload, sampling_rate)\u001B[39m\n\u001B[32m     35\u001B[39m         output_stream = ffmpeg_process.communicate(bpayload)\n\u001B[32m     36\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mffmpeg was not found but is required to load audio files from filename\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merror\u001B[39;00m\n\u001B[32m     38\u001B[39m out_bytes = output_stream[\u001B[32m0\u001B[39m]\n\u001B[32m     39\u001B[39m audio = np.frombuffer(out_bytes, np.float32)\n",
      "\u001B[31mValueError\u001B[39m: ffmpeg was not found but is required to load audio files from filename"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "start_end_text = []\n",
    "\n",
    "for chunk in result['chunk']:\n",
    "    start = chunk['timestamp'][0]\n",
    "    end = chunk['timestamp'][1]\n",
    "    text = chunk['text']\n",
    "    start_end_text.append((start, end, text))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(start_end_text, columns=['start', 'end', 'text'])\n",
    "df.to_csv(\"lsy_audio_2023_58.csv\", index=False,sep=\"|\")\n",
    "display(df)\n"
   ],
   "id": "7637b158d2f2e325"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
